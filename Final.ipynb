{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/train.csv')\n",
    "test_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/test.csv')\n",
    "ID = train_f['ID']\n",
    "ID1 = test_f['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO load and show images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To resize all the training images to a common size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 61151232 into shape (784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9b2b81dc3689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 61151232 into shape (784)"
     ]
    }
   ],
   "source": [
    "train_r = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r.append(image)\n",
    "    \n",
    "train_x = np.stack(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To resize all the test  images to a common size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_resize = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_resize.append(image)\n",
    "    \n",
    "test_x = np.stack(test_resize)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the images to train faster, 255 is the max value, so divide by 255 to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see what is the data distirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIDDLE    0.542751\n",
       "YOUNG     0.336883\n",
       "OLD       0.120366\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sidhraj/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train_f.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building a feed forward model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  InputLayer(input_shape=input_num_units),\n",
    "  Flatten(),\n",
    "  Dense(units=hidden_num_units, activation='relu'),\n",
    "  Dense(units=output_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1536500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 1,538,003\n",
      "Trainable params: 1,538,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19906/19906 [==============================] - 7s 336us/step - loss: 0.8981 - acc: 0.5734\n",
      "Epoch 2/5\n",
      "19906/19906 [==============================] - 7s 336us/step - loss: 0.8496 - acc: 0.5993\n",
      "Epoch 3/5\n",
      "19906/19906 [==============================] - ETA: 0s - loss: 0.8249 - acc: 0.618 - 7s 329us/step - loss: 0.8249 - acc: 0.6189\n",
      "Epoch 4/5\n",
      "19906/19906 [==============================] - 7s 332us/step - loss: 0.8171 - acc: 0.6207\n",
      "Epoch 5/5\n",
      "19906/19906 [==============================] - 7s 330us/step - loss: 0.8100 - acc: 0.6264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22ac1456a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/5\n",
      "15924/15924 [==============================] - 6s 370us/step - loss: 0.8009 - acc: 0.6319 - val_loss: 0.8164 - val_acc: 0.6160\n",
      "Epoch 2/5\n",
      "15924/15924 [==============================] - 6s 349us/step - loss: 0.7986 - acc: 0.6333 - val_loss: 0.7906 - val_acc: 0.6404\n",
      "Epoch 3/5\n",
      "15924/15924 [==============================] - 6s 352us/step - loss: 0.7961 - acc: 0.6372 - val_loss: 0.8282 - val_acc: 0.6042\n",
      "Epoch 4/5\n",
      "15924/15924 [==============================] - 6s 354us/step - loss: 0.7898 - acc: 0.6353 - val_loss: 0.7846 - val_acc: 0.6497\n",
      "Epoch 5/5\n",
      "15924/15924 [==============================] - 6s 352us/step - loss: 0.7844 - acc: 0.6429 - val_loss: 0.8053 - val_acc: 0.6369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a76b9a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/7\n",
      "15924/15924 [==============================] - 6s 371us/step - loss: 0.7472 - acc: 0.6658 - val_loss: 0.7485 - val_acc: 0.6678\n",
      "Epoch 2/7\n",
      "15924/15924 [==============================] - 6s 375us/step - loss: 0.7436 - acc: 0.6696 - val_loss: 0.8008 - val_acc: 0.6231\n",
      "Epoch 3/7\n",
      "15924/15924 [==============================] - 6s 364us/step - loss: 0.7438 - acc: 0.6650 - val_loss: 0.7493 - val_acc: 0.6595\n",
      "Epoch 4/7\n",
      "15924/15924 [==============================] - 6s 363us/step - loss: 0.7395 - acc: 0.6692 - val_loss: 0.7376 - val_acc: 0.6763\n",
      "Epoch 5/7\n",
      "15924/15924 [==============================] - 6s 358us/step - loss: 0.7359 - acc: 0.6711 - val_loss: 0.7386 - val_acc: 0.6710\n",
      "Epoch 6/7\n",
      "15924/15924 [==============================] - 6s 360us/step - loss: 0.7319 - acc: 0.6745 - val_loss: 0.7319 - val_acc: 0.6803\n",
      "Epoch 7/7\n",
      "15924/15924 [==============================] - 6s 359us/step - loss: 0.7303 - acc: 0.6752 - val_loss: 0.7375 - val_acc: 0.6675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a76b99b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=7,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 1s 220us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "pred = lb.inverse_transform(pred)\n",
    "test_f['Class'] = pred\n",
    "test_f.to_csv('sol2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just to compare whether predicted values with original class for training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread(('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)).astype('float32')\n",
    "    image = imresize(image, (128,128))\n",
    "    pred = model.predict_classes(train_x)\n",
    "    orig = train_f.Class[i]\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    print ('Original: ', orig, 'predicted: ', lb.inverse_transform(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data pre processing for MLP (Multi Layer Perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_r2 = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r2.append(image)\n",
    "    \n",
    "train_x2 = np.stack(train_r2)\n",
    "train_x2 /= 255.0\n",
    "\n",
    "train_x2 = train_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_r2 = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_r2.append(image)\n",
    "    \n",
    "    \n",
    "test_x2 = np.stack(test_r2)\n",
    "test_x2 /= 255.0\n",
    "test_x2 = test_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1024, activation=\"relu\", units=1200)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1200, activation=\"relu\", units=1000)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1200, activation=\"softmax\", units=3)`\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 1024 ### the image is 32X32=1024\n",
    "hidden1_num_units = 1500\n",
    "hidden2_num_units = 1000\n",
    "#hidden3_num_units = 1000\n",
    "#hidden4_num_units = 1000\n",
    "hidden5_num_units = 1500\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')## not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 1,052,675\n",
      "Trainable params: 1,052,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting epochs vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17915 samples, validate on 1991 samples\n",
      "Epoch 1/50\n",
      "17915/17915 [==============================] - 16s 893us/step - loss: 1.0377 - acc: 0.5500 - val_loss: 0.8490 - val_acc: 0.6017\n",
      "Epoch 2/50\n",
      "17915/17915 [==============================] - 15s 860us/step - loss: 0.8617 - acc: 0.5882 - val_loss: 0.8361 - val_acc: 0.5962\n",
      "Epoch 3/50\n",
      "17915/17915 [==============================] - 15s 861us/step - loss: 0.8457 - acc: 0.5958 - val_loss: 0.8112 - val_acc: 0.6138\n",
      "Epoch 4/50\n",
      "17915/17915 [==============================] - 17s 943us/step - loss: 0.8343 - acc: 0.5990 - val_loss: 0.8035 - val_acc: 0.6153\n",
      "Epoch 5/50\n",
      "17915/17915 [==============================] - 16s 868us/step - loss: 0.8292 - acc: 0.6021 - val_loss: 0.8142 - val_acc: 0.6228\n",
      "Epoch 6/50\n",
      "17915/17915 [==============================] - 16s 875us/step - loss: 0.8189 - acc: 0.6084 - val_loss: 0.7979 - val_acc: 0.6138\n",
      "Epoch 7/50\n",
      "17915/17915 [==============================] - 16s 884us/step - loss: 0.8170 - acc: 0.6108 - val_loss: 0.8284 - val_acc: 0.5897\n",
      "Epoch 8/50\n",
      "17915/17915 [==============================] - 16s 903us/step - loss: 0.8167 - acc: 0.6170 - val_loss: 0.7919 - val_acc: 0.6288\n",
      "Epoch 9/50\n",
      "17915/17915 [==============================] - 16s 889us/step - loss: 0.8138 - acc: 0.6170 - val_loss: 0.7931 - val_acc: 0.6273\n",
      "Epoch 10/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.8098 - acc: 0.6207 - val_loss: 0.7891 - val_acc: 0.6238\n",
      "Epoch 11/50\n",
      "17915/17915 [==============================] - 17s 935us/step - loss: 0.8104 - acc: 0.6163 - val_loss: 0.7788 - val_acc: 0.6469\n",
      "Epoch 12/50\n",
      "17915/17915 [==============================] - 17s 961us/step - loss: 0.7976 - acc: 0.6241 - val_loss: 0.7810 - val_acc: 0.6308\n",
      "Epoch 13/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7972 - acc: 0.6286 - val_loss: 0.7956 - val_acc: 0.6243\n",
      "Epoch 14/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.8022 - acc: 0.6237 - val_loss: 0.7803 - val_acc: 0.6409\n",
      "Epoch 15/50\n",
      "17915/17915 [==============================] - 18s 979us/step - loss: 0.7886 - acc: 0.6314 - val_loss: 0.7719 - val_acc: 0.6489\n",
      "Epoch 16/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7841 - acc: 0.6316 - val_loss: 0.7621 - val_acc: 0.6560\n",
      "Epoch 17/50\n",
      "17915/17915 [==============================] - 17s 974us/step - loss: 0.7790 - acc: 0.6364 - val_loss: 0.7628 - val_acc: 0.6494\n",
      "Epoch 18/50\n",
      "17915/17915 [==============================] - 17s 963us/step - loss: 0.7753 - acc: 0.6404 - val_loss: 0.7538 - val_acc: 0.6600\n",
      "Epoch 19/50\n",
      "17915/17915 [==============================] - 17s 965us/step - loss: 0.7771 - acc: 0.6371 - val_loss: 0.7654 - val_acc: 0.6484\n",
      "Epoch 20/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7705 - acc: 0.6386 - val_loss: 0.7610 - val_acc: 0.6580\n",
      "Epoch 21/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7755 - acc: 0.6378 - val_loss: 0.7648 - val_acc: 0.6439\n",
      "Epoch 22/50\n",
      "17915/17915 [==============================] - 17s 955us/step - loss: 0.7663 - acc: 0.6437 - val_loss: 0.7569 - val_acc: 0.6514\n",
      "Epoch 23/50\n",
      "17915/17915 [==============================] - 17s 928us/step - loss: 0.7690 - acc: 0.6430 - val_loss: 0.7506 - val_acc: 0.6595\n",
      "Epoch 24/50\n",
      "17915/17915 [==============================] - 15s 832us/step - loss: 0.7682 - acc: 0.6401 - val_loss: 0.7512 - val_acc: 0.6504\n",
      "Epoch 25/50\n",
      "17915/17915 [==============================] - 16s 898us/step - loss: 0.7646 - acc: 0.6413 - val_loss: 0.7591 - val_acc: 0.6519\n",
      "Epoch 26/50\n",
      "17915/17915 [==============================] - 17s 956us/step - loss: 0.7574 - acc: 0.6455 - val_loss: 0.7626 - val_acc: 0.6504\n",
      "Epoch 27/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7553 - acc: 0.6500 - val_loss: 0.7449 - val_acc: 0.6580\n",
      "Epoch 28/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7523 - acc: 0.6511 - val_loss: 0.7504 - val_acc: 0.6660\n",
      "Epoch 29/50\n",
      "17915/17915 [==============================] - 18s 987us/step - loss: 0.7467 - acc: 0.6537 - val_loss: 0.7370 - val_acc: 0.6700\n",
      "Epoch 30/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.7460 - acc: 0.6533 - val_loss: 0.7457 - val_acc: 0.6650\n",
      "Epoch 31/50\n",
      "17915/17915 [==============================] - 17s 971us/step - loss: 0.7539 - acc: 0.6478 - val_loss: 0.7465 - val_acc: 0.6519\n",
      "Epoch 32/50\n",
      "17915/17915 [==============================] - 16s 914us/step - loss: 0.7480 - acc: 0.6487 - val_loss: 0.7455 - val_acc: 0.6570\n",
      "Epoch 33/50\n",
      "17915/17915 [==============================] - 17s 969us/step - loss: 0.7443 - acc: 0.6529 - val_loss: 0.7611 - val_acc: 0.6519\n",
      "Epoch 34/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7477 - acc: 0.6535 - val_loss: 0.7608 - val_acc: 0.6499\n",
      "Epoch 35/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7554 - acc: 0.6476 - val_loss: 0.7547 - val_acc: 0.6429\n",
      "Epoch 36/50\n",
      "17915/17915 [==============================] - 18s 990us/step - loss: 0.7428 - acc: 0.6526 - val_loss: 0.7469 - val_acc: 0.6640\n",
      "Epoch 37/50\n",
      "17915/17915 [==============================] - 17s 933us/step - loss: 0.7379 - acc: 0.6587 - val_loss: 0.7529 - val_acc: 0.6560\n",
      "Epoch 38/50\n",
      "17915/17915 [==============================] - 17s 929us/step - loss: 0.7385 - acc: 0.6602 - val_loss: 0.7504 - val_acc: 0.6575\n",
      "Epoch 39/50\n",
      "17915/17915 [==============================] - 17s 975us/step - loss: 0.7445 - acc: 0.6562 - val_loss: 0.7404 - val_acc: 0.6645\n",
      "Epoch 40/50\n",
      "17915/17915 [==============================] - 17s 960us/step - loss: 0.7329 - acc: 0.6574 - val_loss: 0.7417 - val_acc: 0.6620\n",
      "Epoch 41/50\n",
      "17915/17915 [==============================] - 16s 901us/step - loss: 0.7267 - acc: 0.6653 - val_loss: 0.7378 - val_acc: 0.6665\n",
      "Epoch 42/50\n",
      "17915/17915 [==============================] - 18s 996us/step - loss: 0.7172 - acc: 0.6677 - val_loss: 0.7414 - val_acc: 0.6544\n",
      "Epoch 43/50\n",
      "17915/17915 [==============================] - 18s 978us/step - loss: 0.7309 - acc: 0.6587 - val_loss: 0.7482 - val_acc: 0.6655\n",
      "Epoch 44/50\n",
      "17915/17915 [==============================] - 17s 961us/step - loss: 0.7219 - acc: 0.6651 - val_loss: 0.7316 - val_acc: 0.6640\n",
      "Epoch 45/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.7216 - acc: 0.6662 - val_loss: 0.7343 - val_acc: 0.6705\n",
      "Epoch 46/50\n",
      "17915/17915 [==============================] - 17s 937us/step - loss: 0.7157 - acc: 0.6703 - val_loss: 0.7427 - val_acc: 0.6615\n",
      "Epoch 47/50\n",
      "17915/17915 [==============================] - 17s 927us/step - loss: 0.7167 - acc: 0.6692 - val_loss: 0.7428 - val_acc: 0.6605\n",
      "Epoch 48/50\n",
      "17915/17915 [==============================] - 16s 917us/step - loss: 0.7221 - acc: 0.6674 - val_loss: 0.7457 - val_acc: 0.6620\n",
      "Epoch 49/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7167 - acc: 0.6717 - val_loss: 0.7392 - val_acc: 0.6650\n",
      "Epoch 50/50\n",
      "17915/17915 [==============================] - 18s 991us/step - loss: 0.7079 - acc: 0.6751 - val_loss: 0.7521 - val_acc: 0.6595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a16f32b70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x2, train_y, nb_epoch=epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d586b507a618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 1s 137us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x2)\n",
    "pred = lb.inverse_transform(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Age_Detection_Problem/solMLP.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The accuracy is still under 70, so trying for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (3, 3), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (1, 1), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1024, activation=\"softmax\", units=3)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.8798 - acc: 0.5777 - val_loss: 0.8076 - val_acc: 0.6336\n",
      "Epoch 2/25\n",
      "15924/15924 [==============================] - 44s 3ms/step - loss: 0.8050 - acc: 0.6273 - val_loss: 0.7724 - val_acc: 0.6575\n",
      "Epoch 3/25\n",
      "15924/15924 [==============================] - 27s 2ms/step - loss: 0.7731 - acc: 0.6528 - val_loss: 0.7855 - val_acc: 0.6504\n",
      "Epoch 4/25\n",
      "15924/15924 [==============================] - 20s 1ms/step - loss: 0.7423 - acc: 0.6703 - val_loss: 0.7392 - val_acc: 0.6816\n",
      "Epoch 5/25\n",
      "15924/15924 [==============================] - 33s 2ms/step - loss: 0.7154 - acc: 0.6890 - val_loss: 0.7344 - val_acc: 0.6838\n",
      "Epoch 6/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.6894 - acc: 0.6989 - val_loss: 0.7238 - val_acc: 0.6826\n",
      "Epoch 7/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.6587 - acc: 0.7173 - val_loss: 0.7046 - val_acc: 0.7012\n",
      "Epoch 8/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.6244 - acc: 0.7359 - val_loss: 0.6992 - val_acc: 0.6976\n",
      "Epoch 9/25\n",
      "15924/15924 [==============================] - 40s 2ms/step - loss: 0.5911 - acc: 0.7496 - val_loss: 0.6869 - val_acc: 0.6984\n",
      "Epoch 10/25\n",
      "15924/15924 [==============================] - 34s 2ms/step - loss: 0.5566 - acc: 0.7658 - val_loss: 0.6708 - val_acc: 0.7248\n",
      "Epoch 11/25\n",
      "15924/15924 [==============================] - 36s 2ms/step - loss: 0.5114 - acc: 0.7906 - val_loss: 0.6652 - val_acc: 0.7245\n",
      "Epoch 12/25\n",
      "15924/15924 [==============================] - 37s 2ms/step - loss: 0.4735 - acc: 0.8055 - val_loss: 0.6566 - val_acc: 0.7273\n",
      "Epoch 13/25\n",
      "15924/15924 [==============================] - 45s 3ms/step - loss: 0.4338 - acc: 0.8269 - val_loss: 0.6744 - val_acc: 0.7235\n",
      "Epoch 14/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.3914 - acc: 0.8490 - val_loss: 0.6859 - val_acc: 0.7290\n",
      "Epoch 15/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.3501 - acc: 0.8688 - val_loss: 0.7167 - val_acc: 0.7300\n",
      "Epoch 16/25\n",
      "15924/15924 [==============================] - 43s 3ms/step - loss: 0.3118 - acc: 0.8842 - val_loss: 0.7024 - val_acc: 0.7268\n",
      "Epoch 17/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.2611 - acc: 0.9077 - val_loss: 0.7492 - val_acc: 0.7293\n",
      "Epoch 18/25\n",
      "15924/15924 [==============================] - 49s 3ms/step - loss: 0.2215 - acc: 0.9239 - val_loss: 0.7956 - val_acc: 0.7366\n",
      "Epoch 19/25\n",
      "15924/15924 [==============================] - 45s 3ms/step - loss: 0.1820 - acc: 0.9443 - val_loss: 0.8056 - val_acc: 0.7378\n",
      "Epoch 20/25\n",
      "15924/15924 [==============================] - 37s 2ms/step - loss: 0.1515 - acc: 0.9543 - val_loss: 0.8533 - val_acc: 0.7333\n",
      "Epoch 21/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.1256 - acc: 0.9638 - val_loss: 0.8568 - val_acc: 0.7348\n",
      "Epoch 22/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.0907 - acc: 0.9791 - val_loss: 0.9125 - val_acc: 0.7398\n",
      "Epoch 23/25\n",
      "15924/15924 [==============================] - 46s 3ms/step - loss: 0.0694 - acc: 0.9863 - val_loss: 0.9584 - val_acc: 0.7290\n",
      "Epoch 24/25\n",
      "15924/15924 [==============================] - 36s 2ms/step - loss: 0.0552 - acc: 0.9909 - val_loss: 0.9777 - val_acc: 0.7341\n",
      "Epoch 25/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.0370 - acc: 0.9962 - val_loss: 1.0641 - val_acc: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "train_x3 = train_x2.reshape(-1, 32, 32, 1)\n",
    "#val_x_temp = val_x.reshape(-1, 32, 32, 1) for vslidation data\n",
    "test_x3 = test_x2.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# define vars\n",
    "input_shape = (1024,)\n",
    "input_reshape = (32, 32, 1)\n",
    "\n",
    "conv_num_filters = 4 # 3 #6 #5 #3\n",
    "conv_filter_size = 2 #5\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 1024\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 120\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "#                  5  5      4 4   \n",
    " Convolution2D(25, 3, 3, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "#              25, 5, 5     3  3\n",
    " Convolution2D(25, 1, 1, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "#              25, 4,4     2  2\n",
    " #Convolution2D(25, 5, 5, activation='relu'),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(train_x3, train_y, nb_epoch=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 8s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x3)\n",
    "pred = lb.inverse_transform(pred)\n",
    "\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Age_Detection_Problem/CNN14.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1076px",
    "left": "5.29514px",
    "right": "20px",
    "top": "5.98958px",
    "width": "489px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
