{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    
    ##This problem has a training dataset with 19906 images of Indian actors and actresses. The dataset also has a csv file with
    ##class labels, classifying them in categories as YOUNG/MIDDLE/OLD. The test dataset has 6636 images, and the task is to 
    ###  classify them as YOUNG/MIDDLE/OLD.
    
    
    "from scipy.misc import imread\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/train.csv')\n",
    "test_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/test.csv')\n",
    "ID = train_f['ID']\n",
    "ID1 = test_f['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO load and show images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To resize all the training images to a common size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_r = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r.append(image)\n",
    "    \n",
    "train_x = np.stack(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To resize all the test  images to a common size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_resize = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_resize.append(image)\n",
    "    \n",
    "test_x = np.stack(test_resize)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the images to train faster, 255 is the max value, so divide by 255 to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see what is the data distirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train_f.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building a feed forward model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  InputLayer(input_shape=input_num_units),\n",
    "  Flatten(),\n",
    "  Dense(units=hidden_num_units, activation='relu'),\n",
    "  Dense(units=output_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=7,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "pred = lb.inverse_transform(pred)\n",
    "test_f['Class'] = pred\n",
    "test_f.to_csv('sol2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just to compare whether predicted values with original class for training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread(('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)).astype('float32')\n",
    "    image = imresize(image, (128,128))\n",
    "    pred = model.predict_classes(train_x)\n",
    "    orig = train_f.Class[i]\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    print ('Original: ', orig, 'predicted: ', lb.inverse_transform(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data pre processing for MLP (Multi Layer Perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_r2 = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r2.append(image)\n",
    "    \n",
    "train_x2 = np.stack(train_r2)\n",
    "train_x2 /= 255.0\n",
    "\n",
    "train_x2 = train_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_r2 = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_r2.append(image)\n",
    "    \n",
    "    \n",
    "test_x2 = np.stack(test_r2)\n",
    "test_x2 /= 255.0\n",
    "test_x2 = test_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_num_units = 1024 ### the image is 32X32=1024\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 300\n",
    "#hidden4_num_units = 300\n",
    "#hidden5_num_units = 300\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 150\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')## not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x2, train_y, nb_epoch=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(test_x2)\n",
    "pred = lb.inverse_transform(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Age_Detection_Problem/solMLP.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1076px",
    "left": "5.29514px",
    "right": "20px",
    "top": "5.98958px",
    "width": "489px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
