{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/train.csv')\n",
    "test_f = pd.read_csv('/home/sidhraj/Documents/AV/Age_Detection_Problem/test.csv')\n",
    "ID = train_f['ID']\n",
    "ID1 = test_f['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TO load and show images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD8CAYAAAAVHWrNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22d775a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
     ]
    }
   ],
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },"
     ]
    }
   ],
   "source": [
    "train_r = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r.append(image)\n",
    "    \n",
    "train_x = np.stack(train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To resize all the test  images to a common size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_resize = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_resize.append(image)\n",
    "    \n",
    "test_x = np.stack(test_resize)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize the images to train faster, 255 is the max value, so divide by 255 to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets see what is the data distirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIDDLE    0.542751\n",
       "YOUNG     0.336883\n",
       "OLD       0.120366\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.Class.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sidhraj/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "train_y = lb.fit_transform(train_f.Class)\n",
    "train_y = keras.utils.np_utils.to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building a feed forward model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, InputLayer\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_num_units = (32, 32, 3)\n",
    "hidden_num_units = 500\n",
    "output_num_units = 3\n",
    "epochs = 5\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  InputLayer(input_shape=input_num_units),\n",
    "  Flatten(),\n",
    "  Dense(units=hidden_num_units, activation='relu'),\n",
    "  Dense(units=output_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1536500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 1,538,003\n",
      "Trainable params: 1,538,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19906/19906 [==============================] - 7s 336us/step - loss: 0.8981 - acc: 0.5734\n",
      "Epoch 2/5\n",
      "19906/19906 [==============================] - 7s 336us/step - loss: 0.8496 - acc: 0.5993\n",
      "Epoch 3/5\n",
      "19906/19906 [==============================] - ETA: 0s - loss: 0.8249 - acc: 0.618 - 7s 329us/step - loss: 0.8249 - acc: 0.6189\n",
      "Epoch 4/5\n",
      "19906/19906 [==============================] - 7s 332us/step - loss: 0.8171 - acc: 0.6207\n",
      "Epoch 5/5\n",
      "19906/19906 [==============================] - 7s 330us/step - loss: 0.8100 - acc: 0.6264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22ac1456a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/5\n",
      "15924/15924 [==============================] - 6s 370us/step - loss: 0.8009 - acc: 0.6319 - val_loss: 0.8164 - val_acc: 0.6160\n",
      "Epoch 2/5\n",
      "15924/15924 [==============================] - 6s 349us/step - loss: 0.7986 - acc: 0.6333 - val_loss: 0.7906 - val_acc: 0.6404\n",
      "Epoch 3/5\n",
      "15924/15924 [==============================] - 6s 352us/step - loss: 0.7961 - acc: 0.6372 - val_loss: 0.8282 - val_acc: 0.6042\n",
      "Epoch 4/5\n",
      "15924/15924 [==============================] - 6s 354us/step - loss: 0.7898 - acc: 0.6353 - val_loss: 0.7846 - val_acc: 0.6497\n",
      "Epoch 5/5\n",
      "15924/15924 [==============================] - 6s 352us/step - loss: 0.7844 - acc: 0.6429 - val_loss: 0.8053 - val_acc: 0.6369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a76b9a58>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/7\n",
      "15924/15924 [==============================] - 6s 371us/step - loss: 0.7472 - acc: 0.6658 - val_loss: 0.7485 - val_acc: 0.6678\n",
      "Epoch 2/7\n",
      "15924/15924 [==============================] - 6s 375us/step - loss: 0.7436 - acc: 0.6696 - val_loss: 0.8008 - val_acc: 0.6231\n",
      "Epoch 3/7\n",
      "15924/15924 [==============================] - 6s 364us/step - loss: 0.7438 - acc: 0.6650 - val_loss: 0.7493 - val_acc: 0.6595\n",
      "Epoch 4/7\n",
      "15924/15924 [==============================] - 6s 363us/step - loss: 0.7395 - acc: 0.6692 - val_loss: 0.7376 - val_acc: 0.6763\n",
      "Epoch 5/7\n",
      "15924/15924 [==============================] - 6s 358us/step - loss: 0.7359 - acc: 0.6711 - val_loss: 0.7386 - val_acc: 0.6710\n",
      "Epoch 6/7\n",
      "15924/15924 [==============================] - 6s 360us/step - loss: 0.7319 - acc: 0.6745 - val_loss: 0.7319 - val_acc: 0.6803\n",
      "Epoch 7/7\n",
      "15924/15924 [==============================] - 6s 359us/step - loss: 0.7303 - acc: 0.6752 - val_loss: 0.7375 - val_acc: 0.6675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a76b99b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=batch_size,epochs=7,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 1s 220us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "pred = lb.inverse_transform(pred)\n",
    "test_f['Class'] = pred\n",
    "test_f.to_csv('sol2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## just to compare whether predicted values with original class for training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread(('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file)).astype('float32')\n",
    "    image = imresize(image, (128,128))\n",
    "    pred = model.predict_classes(train_x)\n",
    "    orig = train_f.Class[i]\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    print ('Original: ', orig, 'predicted: ', lb.inverse_transform(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data pre processing for MLP (Multi Layer Perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_r2 = []\n",
    "for i in range(19906):\n",
    "    file = ID[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Train/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage\n",
    "    train_r2.append(image)\n",
    "    \n",
    "train_x2 = np.stack(train_r2)\n",
    "train_x2 /= 255.0\n",
    "\n",
    "train_x2 = train_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Processing for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_r2 = []\n",
    "for i in range(6636):\n",
    "    file = ID1[i]\n",
    "    image = imread('/home/sidhraj/Documents/AV/Age_Detection_Problem/Test/' + file, flatten=True)\n",
    "    image = imresize(image, (32, 32))\n",
    "    image = image.astype('float32') # this will help us in later stage  \n",
    "    test_r2.append(image)\n",
    "    \n",
    "    \n",
    "test_x2 = np.stack(test_r2)\n",
    "test_x2 /= 255.0\n",
    "test_x2 = test_x2.reshape(-1, 1024).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1024, activation=\"relu\", units=1200)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1200, activation=\"relu\", units=1000)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1200, activation=\"softmax\", units=3)`\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 1024 ### the image is 32X32=1024\n",
    "hidden1_num_units = 1500\n",
    "hidden2_num_units = 1000\n",
    "#hidden3_num_units = 1000\n",
    "#hidden4_num_units = 1000\n",
    "hidden5_num_units = 1500\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 200\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    " #Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " #Dropout(dropout_ratio),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')## not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 1,052,675\n",
      "Trainable params: 1,052,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting epochs vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17915 samples, validate on 1991 samples\n",
      "Epoch 1/50\n",
      "17915/17915 [==============================] - 16s 893us/step - loss: 1.0377 - acc: 0.5500 - val_loss: 0.8490 - val_acc: 0.6017\n",
      "Epoch 2/50\n",
      "17915/17915 [==============================] - 15s 860us/step - loss: 0.8617 - acc: 0.5882 - val_loss: 0.8361 - val_acc: 0.5962\n",
      "Epoch 3/50\n",
      "17915/17915 [==============================] - 15s 861us/step - loss: 0.8457 - acc: 0.5958 - val_loss: 0.8112 - val_acc: 0.6138\n",
      "Epoch 4/50\n",
      "17915/17915 [==============================] - 17s 943us/step - loss: 0.8343 - acc: 0.5990 - val_loss: 0.8035 - val_acc: 0.6153\n",
      "Epoch 5/50\n",
      "17915/17915 [==============================] - 16s 868us/step - loss: 0.8292 - acc: 0.6021 - val_loss: 0.8142 - val_acc: 0.6228\n",
      "Epoch 6/50\n",
      "17915/17915 [==============================] - 16s 875us/step - loss: 0.8189 - acc: 0.6084 - val_loss: 0.7979 - val_acc: 0.6138\n",
      "Epoch 7/50\n",
      "17915/17915 [==============================] - 16s 884us/step - loss: 0.8170 - acc: 0.6108 - val_loss: 0.8284 - val_acc: 0.5897\n",
      "Epoch 8/50\n",
      "17915/17915 [==============================] - 16s 903us/step - loss: 0.8167 - acc: 0.6170 - val_loss: 0.7919 - val_acc: 0.6288\n",
      "Epoch 9/50\n",
      "17915/17915 [==============================] - 16s 889us/step - loss: 0.8138 - acc: 0.6170 - val_loss: 0.7931 - val_acc: 0.6273\n",
      "Epoch 10/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.8098 - acc: 0.6207 - val_loss: 0.7891 - val_acc: 0.6238\n",
      "Epoch 11/50\n",
      "17915/17915 [==============================] - 17s 935us/step - loss: 0.8104 - acc: 0.6163 - val_loss: 0.7788 - val_acc: 0.6469\n",
      "Epoch 12/50\n",
      "17915/17915 [==============================] - 17s 961us/step - loss: 0.7976 - acc: 0.6241 - val_loss: 0.7810 - val_acc: 0.6308\n",
      "Epoch 13/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7972 - acc: 0.6286 - val_loss: 0.7956 - val_acc: 0.6243\n",
      "Epoch 14/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.8022 - acc: 0.6237 - val_loss: 0.7803 - val_acc: 0.6409\n",
      "Epoch 15/50\n",
      "17915/17915 [==============================] - 18s 979us/step - loss: 0.7886 - acc: 0.6314 - val_loss: 0.7719 - val_acc: 0.6489\n",
      "Epoch 16/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7841 - acc: 0.6316 - val_loss: 0.7621 - val_acc: 0.6560\n",
      "Epoch 17/50\n",
      "17915/17915 [==============================] - 17s 974us/step - loss: 0.7790 - acc: 0.6364 - val_loss: 0.7628 - val_acc: 0.6494\n",
      "Epoch 18/50\n",
      "17915/17915 [==============================] - 17s 963us/step - loss: 0.7753 - acc: 0.6404 - val_loss: 0.7538 - val_acc: 0.6600\n",
      "Epoch 19/50\n",
      "17915/17915 [==============================] - 17s 965us/step - loss: 0.7771 - acc: 0.6371 - val_loss: 0.7654 - val_acc: 0.6484\n",
      "Epoch 20/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7705 - acc: 0.6386 - val_loss: 0.7610 - val_acc: 0.6580\n",
      "Epoch 21/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7755 - acc: 0.6378 - val_loss: 0.7648 - val_acc: 0.6439\n",
      "Epoch 22/50\n",
      "17915/17915 [==============================] - 17s 955us/step - loss: 0.7663 - acc: 0.6437 - val_loss: 0.7569 - val_acc: 0.6514\n",
      "Epoch 23/50\n",
      "17915/17915 [==============================] - 17s 928us/step - loss: 0.7690 - acc: 0.6430 - val_loss: 0.7506 - val_acc: 0.6595\n",
      "Epoch 24/50\n",
      "17915/17915 [==============================] - 15s 832us/step - loss: 0.7682 - acc: 0.6401 - val_loss: 0.7512 - val_acc: 0.6504\n",
      "Epoch 25/50\n",
      "17915/17915 [==============================] - 16s 898us/step - loss: 0.7646 - acc: 0.6413 - val_loss: 0.7591 - val_acc: 0.6519\n",
      "Epoch 26/50\n",
      "17915/17915 [==============================] - 17s 956us/step - loss: 0.7574 - acc: 0.6455 - val_loss: 0.7626 - val_acc: 0.6504\n",
      "Epoch 27/50\n",
      "17915/17915 [==============================] - 19s 1ms/step - loss: 0.7553 - acc: 0.6500 - val_loss: 0.7449 - val_acc: 0.6580\n",
      "Epoch 28/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7523 - acc: 0.6511 - val_loss: 0.7504 - val_acc: 0.6660\n",
      "Epoch 29/50\n",
      "17915/17915 [==============================] - 18s 987us/step - loss: 0.7467 - acc: 0.6537 - val_loss: 0.7370 - val_acc: 0.6700\n",
      "Epoch 30/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.7460 - acc: 0.6533 - val_loss: 0.7457 - val_acc: 0.6650\n",
      "Epoch 31/50\n",
      "17915/17915 [==============================] - 17s 971us/step - loss: 0.7539 - acc: 0.6478 - val_loss: 0.7465 - val_acc: 0.6519\n",
      "Epoch 32/50\n",
      "17915/17915 [==============================] - 16s 914us/step - loss: 0.7480 - acc: 0.6487 - val_loss: 0.7455 - val_acc: 0.6570\n",
      "Epoch 33/50\n",
      "17915/17915 [==============================] - 17s 969us/step - loss: 0.7443 - acc: 0.6529 - val_loss: 0.7611 - val_acc: 0.6519\n",
      "Epoch 34/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7477 - acc: 0.6535 - val_loss: 0.7608 - val_acc: 0.6499\n",
      "Epoch 35/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7554 - acc: 0.6476 - val_loss: 0.7547 - val_acc: 0.6429\n",
      "Epoch 36/50\n",
      "17915/17915 [==============================] - 18s 990us/step - loss: 0.7428 - acc: 0.6526 - val_loss: 0.7469 - val_acc: 0.6640\n",
      "Epoch 37/50\n",
      "17915/17915 [==============================] - 17s 933us/step - loss: 0.7379 - acc: 0.6587 - val_loss: 0.7529 - val_acc: 0.6560\n",
      "Epoch 38/50\n",
      "17915/17915 [==============================] - 17s 929us/step - loss: 0.7385 - acc: 0.6602 - val_loss: 0.7504 - val_acc: 0.6575\n",
      "Epoch 39/50\n",
      "17915/17915 [==============================] - 17s 975us/step - loss: 0.7445 - acc: 0.6562 - val_loss: 0.7404 - val_acc: 0.6645\n",
      "Epoch 40/50\n",
      "17915/17915 [==============================] - 17s 960us/step - loss: 0.7329 - acc: 0.6574 - val_loss: 0.7417 - val_acc: 0.6620\n",
      "Epoch 41/50\n",
      "17915/17915 [==============================] - 16s 901us/step - loss: 0.7267 - acc: 0.6653 - val_loss: 0.7378 - val_acc: 0.6665\n",
      "Epoch 42/50\n",
      "17915/17915 [==============================] - 18s 996us/step - loss: 0.7172 - acc: 0.6677 - val_loss: 0.7414 - val_acc: 0.6544\n",
      "Epoch 43/50\n",
      "17915/17915 [==============================] - 18s 978us/step - loss: 0.7309 - acc: 0.6587 - val_loss: 0.7482 - val_acc: 0.6655\n",
      "Epoch 44/50\n",
      "17915/17915 [==============================] - 17s 961us/step - loss: 0.7219 - acc: 0.6651 - val_loss: 0.7316 - val_acc: 0.6640\n",
      "Epoch 45/50\n",
      "17915/17915 [==============================] - 18s 993us/step - loss: 0.7216 - acc: 0.6662 - val_loss: 0.7343 - val_acc: 0.6705\n",
      "Epoch 46/50\n",
      "17915/17915 [==============================] - 17s 937us/step - loss: 0.7157 - acc: 0.6703 - val_loss: 0.7427 - val_acc: 0.6615\n",
      "Epoch 47/50\n",
      "17915/17915 [==============================] - 17s 927us/step - loss: 0.7167 - acc: 0.6692 - val_loss: 0.7428 - val_acc: 0.6605\n",
      "Epoch 48/50\n",
      "17915/17915 [==============================] - 16s 917us/step - loss: 0.7221 - acc: 0.6674 - val_loss: 0.7457 - val_acc: 0.6620\n",
      "Epoch 49/50\n",
      "17915/17915 [==============================] - 18s 1ms/step - loss: 0.7167 - acc: 0.6717 - val_loss: 0.7392 - val_acc: 0.6650\n",
      "Epoch 50/50\n",
      "17915/17915 [==============================] - 18s 991us/step - loss: 0.7079 - acc: 0.6751 - val_loss: 0.7521 - val_acc: 0.6595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a16f32b70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x2, train_y, nb_epoch=epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-d586b507a618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 1s 137us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x2)\n",
    "pred = lb.inverse_transform(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Age_Detection_Problem/solMLP.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The accuracy is still under 70, so trying for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (3, 3), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (1, 1), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1024)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=1024, activation=\"softmax\", units=3)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15924 samples, validate on 3982 samples\n",
      "Epoch 1/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.8798 - acc: 0.5777 - val_loss: 0.8076 - val_acc: 0.6336\n",
      "Epoch 2/25\n",
      "15924/15924 [==============================] - 44s 3ms/step - loss: 0.8050 - acc: 0.6273 - val_loss: 0.7724 - val_acc: 0.6575\n",
      "Epoch 3/25\n",
      "15924/15924 [==============================] - 27s 2ms/step - loss: 0.7731 - acc: 0.6528 - val_loss: 0.7855 - val_acc: 0.6504\n",
      "Epoch 4/25\n",
      "15924/15924 [==============================] - 20s 1ms/step - loss: 0.7423 - acc: 0.6703 - val_loss: 0.7392 - val_acc: 0.6816\n",
      "Epoch 5/25\n",
      "15924/15924 [==============================] - 33s 2ms/step - loss: 0.7154 - acc: 0.6890 - val_loss: 0.7344 - val_acc: 0.6838\n",
      "Epoch 6/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.6894 - acc: 0.6989 - val_loss: 0.7238 - val_acc: 0.6826\n",
      "Epoch 7/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.6587 - acc: 0.7173 - val_loss: 0.7046 - val_acc: 0.7012\n",
      "Epoch 8/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.6244 - acc: 0.7359 - val_loss: 0.6992 - val_acc: 0.6976\n",
      "Epoch 9/25\n",
      "15924/15924 [==============================] - 40s 2ms/step - loss: 0.5911 - acc: 0.7496 - val_loss: 0.6869 - val_acc: 0.6984\n",
      "Epoch 10/25\n",
      "15924/15924 [==============================] - 34s 2ms/step - loss: 0.5566 - acc: 0.7658 - val_loss: 0.6708 - val_acc: 0.7248\n",
      "Epoch 11/25\n",
      "15924/15924 [==============================] - 36s 2ms/step - loss: 0.5114 - acc: 0.7906 - val_loss: 0.6652 - val_acc: 0.7245\n",
      "Epoch 12/25\n",
      "15924/15924 [==============================] - 37s 2ms/step - loss: 0.4735 - acc: 0.8055 - val_loss: 0.6566 - val_acc: 0.7273\n",
      "Epoch 13/25\n",
      "15924/15924 [==============================] - 45s 3ms/step - loss: 0.4338 - acc: 0.8269 - val_loss: 0.6744 - val_acc: 0.7235\n",
      "Epoch 14/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.3914 - acc: 0.8490 - val_loss: 0.6859 - val_acc: 0.7290\n",
      "Epoch 15/25\n",
      "15924/15924 [==============================] - 40s 3ms/step - loss: 0.3501 - acc: 0.8688 - val_loss: 0.7167 - val_acc: 0.7300\n",
      "Epoch 16/25\n",
      "15924/15924 [==============================] - 43s 3ms/step - loss: 0.3118 - acc: 0.8842 - val_loss: 0.7024 - val_acc: 0.7268\n",
      "Epoch 17/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.2611 - acc: 0.9077 - val_loss: 0.7492 - val_acc: 0.7293\n",
      "Epoch 18/25\n",
      "15924/15924 [==============================] - 49s 3ms/step - loss: 0.2215 - acc: 0.9239 - val_loss: 0.7956 - val_acc: 0.7366\n",
      "Epoch 19/25\n",
      "15924/15924 [==============================] - 45s 3ms/step - loss: 0.1820 - acc: 0.9443 - val_loss: 0.8056 - val_acc: 0.7378\n",
      "Epoch 20/25\n",
      "15924/15924 [==============================] - 37s 2ms/step - loss: 0.1515 - acc: 0.9543 - val_loss: 0.8533 - val_acc: 0.7333\n",
      "Epoch 21/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.1256 - acc: 0.9638 - val_loss: 0.8568 - val_acc: 0.7348\n",
      "Epoch 22/25\n",
      "15924/15924 [==============================] - 42s 3ms/step - loss: 0.0907 - acc: 0.9791 - val_loss: 0.9125 - val_acc: 0.7398\n",
      "Epoch 23/25\n",
      "15924/15924 [==============================] - 46s 3ms/step - loss: 0.0694 - acc: 0.9863 - val_loss: 0.9584 - val_acc: 0.7290\n",
      "Epoch 24/25\n",
      "15924/15924 [==============================] - 36s 2ms/step - loss: 0.0552 - acc: 0.9909 - val_loss: 0.9777 - val_acc: 0.7341\n",
      "Epoch 25/25\n",
      "15924/15924 [==============================] - 38s 2ms/step - loss: 0.0370 - acc: 0.9962 - val_loss: 1.0641 - val_acc: 0.7333\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "train_x3 = train_x2.reshape(-1, 32, 32, 1)\n",
    "#val_x_temp = val_x.reshape(-1, 32, 32, 1) for vslidation data\n",
    "test_x3 = test_x2.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# define vars\n",
    "input_shape = (1024,)\n",
    "input_reshape = (32, 32, 1)\n",
    "\n",
    "conv_num_filters = 4 # 3 #6 #5 #3\n",
    "conv_filter_size = 2 #5\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 1024\n",
    "output_num_units = 3\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 120\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "#                  5  5      4 4   \n",
    " Convolution2D(25, 3, 3, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "#              25, 5, 5     3  3\n",
    " Convolution2D(25, 1, 1, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "#              25, 4,4     2  2\n",
    " #Convolution2D(25, 5, 5, activation='relu'),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(train_x3, train_y, nb_epoch=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636/6636 [==============================] - 8s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x3)\n",
    "pred = lb.inverse_transform(pred)\n",
    "\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Age_Detection_Problem/CNN14.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1076px",
    "left": "5.29514px",
    "right": "20px",
    "top": "5.98958px",
    "width": "489px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
