{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  In this problem we need to identify the digit in given images. We have total 70,000 images, \n",
    "#out of which 49,000 are part of train images with the label of digit and rest 21,000 images \n",
    "# are unlabeled (known as test images). Now, We need to identify the digit for test images. \n",
    "#Public and Private split for test images are 40:60 and evaluation metric of this challenge is accuracy. \n",
    "\n",
    "#About Data:\n",
    "\n",
    "#The data set used for this problem is from the populat MNIST data set. \n",
    "# Developed by Yann LeCun, Corina Cortes and Christopher Burger for evaluating machine learning model\n",
    "# on the handwritten digit classification problem. It is a widely used data set in the machine learning \n",
    "# community. For more details about the data set, read here http://bit.ly/1REjJgL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the images are 28X28 size and are in .png format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting the warning: RuntimeWarning: compiletime version 3.5 of module \n",
    "#'tensorflow.python.framework.fast_tensor_util' does not match\n",
    "# runtime version 3.6\n",
    "# To supress the warning :\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reproducing the results, setting the seed\n",
    "seed = 34\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the directories: for data, submission\n",
    "\n",
    "root_dir = os.path.abspath('/home/sidhraj/Documents/AV/Identify Digits/')\n",
    "data_dir = os.path.join(root_dir, 'Data')\n",
    "sub_dir = os.path.join(root_dir, 'Submission')\n",
    "\n",
    "# check for existence of the directories\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)\n",
    "os.path.exists(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBI/hBI/hBI/hBI/hBI/hPoPUl5UxQRVF7IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd2431d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just to check how the image looks:\n",
    "\n",
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'train', img_name)\n",
    "img = imread(filepath, flatten=True)\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   63.,  105.,  229.,  254.,\n",
       "         254.,  254.,  237.,  105.,  105.,   87.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   22.,  175.,  235.,  254.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  253.,  245.,  121.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   88.,  195.,  253.,  253.,  254.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  248.,  238.,  149.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,  134.,  253.,  253.,  253.,  254.,  253.,  253.,\n",
       "         195.,  133.,  218.,  253.,   93.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   27.,  240.,  253.,  253.,  253.,  179.,   55.,   29.,\n",
       "          16.,    0.,   21.,   29.,    2.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           9.,  145.,  253.,  253.,  253.,  253.,   31.,    6.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          76.,  253.,  253.,  253.,  253.,  253.,  254.,  124.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           4.,  183.,  253.,  253.,  253.,  253.,  255.,  250.,  231.,\n",
       "          48.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   60.,  232.,  253.,  253.,  253.,  254.,  253.,  253.,\n",
       "         154.,    6.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   56.,  104.,  104.,  192.,  254.,  253.,  253.,\n",
       "         253.,   29.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  194.,  254.,  254.,\n",
       "         254.,   91.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  105.,  253.,  253.,\n",
       "         253.,  178.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    7.,   15.,    6.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  202.,  253.,  253.,\n",
       "         253.,   81.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  176.,  253.,  159.,    0.,\n",
       "           0.,    0.,    0.,    0.,   22.,  120.,  254.,  253.,  253.,\n",
       "         195.,   16.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  254.,  253.,  242.,   40.,\n",
       "           0.,    0.,    0.,   27.,  195.,  253.,  254.,  253.,  249.,\n",
       "          95.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  255.,  253.,  253.,  218.,\n",
       "         179.,   92.,  179.,  206.,  253.,  253.,  255.,  210.,   70.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  254.,  253.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  253.,  253.,  254.,  113.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  201.,  253.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  237.,  163.,   14.,    3.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,   25.,  220.,  253.,  253.,\n",
       "         213.,  208.,  208.,  155.,   48.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,   86.,  104.,  104.,\n",
       "          12.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img\n",
    "# internal representation of the above image as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converting the test and train images to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_numpy = []\n",
    "for i in train.filename:  # filename is the ID column in csv file  train\n",
    "    image_path = os.path.join(data_dir, 'train', i) ## train is the folder containing images\n",
    "    image = imread(image_path, flatten=True) ## to remove color from images flatten=True\n",
    "    image = image.astype('float32')\n",
    "    train_numpy.append(image)\n",
    "    \n",
    "train_x = np.stack(train_numpy)\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "\n",
    "test_numpy = []\n",
    "for i in test.filename:\n",
    "    image_path = os.path.join(data_dir, 'test', i)\n",
    "    image = imread(image_path, flatten=True)\n",
    "    image = image.astype('float32')\n",
    "    test_numpy.append(image)\n",
    "    \n",
    "test_x = np.stack(test_numpy)\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating the train and validation set\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train.label.values[:split_size], train.label.values[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300    3\n",
       "34301    1\n",
       "34302    6\n",
       "34303    8\n",
       "34304    3\n",
       "34305    8\n",
       "34306    8\n",
       "34307    9\n",
       "34308    3\n",
       "34309    8\n",
       "34310    4\n",
       "34311    6\n",
       "34312    6\n",
       "34313    3\n",
       "34314    6\n",
       "34315    7\n",
       "34316    5\n",
       "34317    3\n",
       "34318    0\n",
       "34319    3\n",
       "34320    9\n",
       "34321    3\n",
       "34322    8\n",
       "34323    8\n",
       "34324    7\n",
       "34325    4\n",
       "34326    3\n",
       "34327    8\n",
       "34328    6\n",
       "34329    5\n",
       "        ..\n",
       "48970    7\n",
       "48971    5\n",
       "48972    0\n",
       "48973    1\n",
       "48974    4\n",
       "48975    1\n",
       "48976    7\n",
       "48977    5\n",
       "48978    6\n",
       "48979    5\n",
       "48980    6\n",
       "48981    3\n",
       "48982    5\n",
       "48983    5\n",
       "48984    9\n",
       "48985    2\n",
       "48986    9\n",
       "48987    0\n",
       "48988    0\n",
       "48989    7\n",
       "48990    0\n",
       "48991    1\n",
       "48992    1\n",
       "48993    6\n",
       "48994    9\n",
       "48995    2\n",
       "48996    4\n",
       "48997    9\n",
       "48998    3\n",
       "48999    0\n",
       "Name: label, Length: 14700, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]\n",
    "train.label.iloc[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=50)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "# import keras modules\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# create model\n",
    "model = Sequential([\n",
    "  Dense(output_dim=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    "  Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "34300/34300 [==============================] - 2s 60us/step - loss: 0.5478 - acc: 0.8512 - val_loss: 0.3111 - val_acc: 0.9140\n",
      "Epoch 2/5\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.2580 - acc: 0.9274 - val_loss: 0.2461 - val_acc: 0.9320\n",
      "Epoch 3/5\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.2048 - acc: 0.9424 - val_loss: 0.2103 - val_acc: 0.9422\n",
      "Epoch 4/5\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.1715 - acc: 0.9522 - val_loss: 0.1835 - val_acc: 0.9483\n",
      "Epoch 5/5\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.1476 - acc: 0.9589 - val_loss: 0.1734 - val_acc: 0.9509\n",
      "21000/21000 [==============================] - 1s 26us/step\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))\n",
    "pred = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = lb.inverse_transform(pred)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/KEras1.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 8.39229\n",
      "Epoch: 2 cost = 1.73185\n",
      "Epoch: 3 cost = 0.92921\n",
      "Epoch: 4 cost = 0.60320\n",
      "Epoch: 5 cost = 0.39541\n",
      "\n",
      "Training complete!\n",
      "Validation Accuracy: 0.956939\n"
     ]
    }
   ],
   "source": [
    "#Another model, the prevoous model gave 95% accuracy on test data set\n",
    "\n",
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 0s 21us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras2.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##The accuracy did not improve much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=50)`\n",
      "  \n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"softmax\", units=10)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "34300/34300 [==============================] - 3s 79us/step - loss: 0.5828 - acc: 0.8287 - val_loss: 0.2529 - val_acc: 0.9295\n",
      "Epoch 2/5\n",
      "34300/34300 [==============================] - 2s 57us/step - loss: 0.2194 - acc: 0.9354 - val_loss: 0.1956 - val_acc: 0.9457\n",
      "Epoch 3/5\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1576 - acc: 0.9534 - val_loss: 0.1797 - val_acc: 0.9501\n",
      "Epoch 4/5\n",
      "34300/34300 [==============================] - 2s 57us/step - loss: 0.1323 - acc: 0.9605 - val_loss: 0.1487 - val_acc: 0.9569\n",
      "Epoch 5/5\n",
      "34300/34300 [==============================] - 2s 57us/step - loss: 0.1123 - acc: 0.9660 - val_loss: 0.1436 - val_acc: 0.9570\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 41us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras3.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## no improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=50)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"softmax\", units=10)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "34300/34300 [==============================] - 4s 119us/step - loss: 1.2152 - acc: 0.5756 - val_loss: 0.3812 - val_acc: 0.8974\n",
      "Epoch 2/5\n",
      "34300/34300 [==============================] - 4s 103us/step - loss: 0.4961 - acc: 0.8584 - val_loss: 0.2855 - val_acc: 0.9201\n",
      "Epoch 3/5\n",
      "34300/34300 [==============================] - 3s 74us/step - loss: 0.3851 - acc: 0.8957 - val_loss: 0.2429 - val_acc: 0.9331\n",
      "Epoch 4/5\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.3328 - acc: 0.9118 - val_loss: 0.2156 - val_acc: 0.9427\n",
      "Epoch 5/5\n",
      "34300/34300 [==============================] - 3s 77us/step - loss: 0.2930 - acc: 0.9234 - val_loss: 0.2163 - val_acc: 0.9433\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(dropout_ratio),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d_with_drop = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 1s 68us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras4.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=50)`\n",
      "  del sys.path[0]\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"softmax\", units=10)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/50\n",
      "34300/34300 [==============================] - 3s 97us/step - loss: 1.1599 - acc: 0.6032 - val_loss: 0.3870 - val_acc: 0.8907\n",
      "Epoch 2/50\n",
      "34300/34300 [==============================] - 4s 103us/step - loss: 0.4835 - acc: 0.8634 - val_loss: 0.2759 - val_acc: 0.9236\n",
      "Epoch 3/50\n",
      "34300/34300 [==============================] - 3s 86us/step - loss: 0.3666 - acc: 0.9023 - val_loss: 0.2432 - val_acc: 0.9346\n",
      "Epoch 4/50\n",
      "34300/34300 [==============================] - 3s 84us/step - loss: 0.3056 - acc: 0.9208 - val_loss: 0.2189 - val_acc: 0.9413\n",
      "Epoch 5/50\n",
      "34300/34300 [==============================] - 3s 97us/step - loss: 0.2799 - acc: 0.9268 - val_loss: 0.2057 - val_acc: 0.9450\n",
      "Epoch 6/50\n",
      "34300/34300 [==============================] - 3s 79us/step - loss: 0.2597 - acc: 0.9331 - val_loss: 0.1887 - val_acc: 0.9499\n",
      "Epoch 7/50\n",
      "34300/34300 [==============================] - 3s 84us/step - loss: 0.2362 - acc: 0.9392 - val_loss: 0.1825 - val_acc: 0.9518\n",
      "Epoch 8/50\n",
      "34300/34300 [==============================] - 3s 78us/step - loss: 0.2225 - acc: 0.9426 - val_loss: 0.1793 - val_acc: 0.9538\n",
      "Epoch 9/50\n",
      "34300/34300 [==============================] - 4s 113us/step - loss: 0.2107 - acc: 0.9449 - val_loss: 0.1714 - val_acc: 0.9544\n",
      "Epoch 10/50\n",
      "34300/34300 [==============================] - 3s 94us/step - loss: 0.1997 - acc: 0.9476 - val_loss: 0.1689 - val_acc: 0.9571\n",
      "Epoch 11/50\n",
      "34300/34300 [==============================] - 3s 89us/step - loss: 0.1917 - acc: 0.9500 - val_loss: 0.1724 - val_acc: 0.9556\n",
      "Epoch 12/50\n",
      "34300/34300 [==============================] - 4s 115us/step - loss: 0.1857 - acc: 0.9515 - val_loss: 0.1582 - val_acc: 0.9595\n",
      "Epoch 13/50\n",
      "34300/34300 [==============================] - 3s 80us/step - loss: 0.1785 - acc: 0.9543 - val_loss: 0.1586 - val_acc: 0.9603\n",
      "Epoch 14/50\n",
      "34300/34300 [==============================] - 3s 86us/step - loss: 0.1715 - acc: 0.9554 - val_loss: 0.1583 - val_acc: 0.9593\n",
      "Epoch 15/50\n",
      "34300/34300 [==============================] - 3s 80us/step - loss: 0.1716 - acc: 0.9555 - val_loss: 0.1635 - val_acc: 0.9595\n",
      "Epoch 16/50\n",
      "34300/34300 [==============================] - 3s 89us/step - loss: 0.1614 - acc: 0.9571 - val_loss: 0.1553 - val_acc: 0.9606\n",
      "Epoch 17/50\n",
      "34300/34300 [==============================] - 4s 125us/step - loss: 0.1573 - acc: 0.9584 - val_loss: 0.1602 - val_acc: 0.9595\n",
      "Epoch 18/50\n",
      "34300/34300 [==============================] - 4s 115us/step - loss: 0.1523 - acc: 0.9597 - val_loss: 0.1537 - val_acc: 0.9625\n",
      "Epoch 19/50\n",
      "34300/34300 [==============================] - 3s 89us/step - loss: 0.1494 - acc: 0.9608 - val_loss: 0.1583 - val_acc: 0.9600\n",
      "Epoch 20/50\n",
      "34300/34300 [==============================] - 3s 84us/step - loss: 0.1461 - acc: 0.9611 - val_loss: 0.1581 - val_acc: 0.9612\n",
      "Epoch 21/50\n",
      "34300/34300 [==============================] - 3s 82us/step - loss: 0.1451 - acc: 0.9624 - val_loss: 0.1607 - val_acc: 0.9588\n",
      "Epoch 22/50\n",
      "34300/34300 [==============================] - 3s 80us/step - loss: 0.1457 - acc: 0.9615 - val_loss: 0.1482 - val_acc: 0.9622\n",
      "Epoch 23/50\n",
      "34300/34300 [==============================] - 4s 126us/step - loss: 0.1428 - acc: 0.9620 - val_loss: 0.1471 - val_acc: 0.9639\n",
      "Epoch 24/50\n",
      "34300/34300 [==============================] - 4s 120us/step - loss: 0.1367 - acc: 0.9634 - val_loss: 0.1507 - val_acc: 0.9636\n",
      "Epoch 25/50\n",
      "34300/34300 [==============================] - 3s 89us/step - loss: 0.1383 - acc: 0.9636 - val_loss: 0.1508 - val_acc: 0.9620\n",
      "Epoch 26/50\n",
      "34300/34300 [==============================] - 4s 117us/step - loss: 0.1299 - acc: 0.9648 - val_loss: 0.1588 - val_acc: 0.9616\n",
      "Epoch 27/50\n",
      "34300/34300 [==============================] - 3s 91us/step - loss: 0.1296 - acc: 0.9647 - val_loss: 0.1525 - val_acc: 0.9634\n",
      "Epoch 28/50\n",
      "34300/34300 [==============================] - 4s 103us/step - loss: 0.1286 - acc: 0.9658 - val_loss: 0.1521 - val_acc: 0.9632\n",
      "Epoch 29/50\n",
      "34300/34300 [==============================] - 4s 102us/step - loss: 0.1270 - acc: 0.9660 - val_loss: 0.1587 - val_acc: 0.9621\n",
      "Epoch 30/50\n",
      "34300/34300 [==============================] - 4s 112us/step - loss: 0.1262 - acc: 0.9664 - val_loss: 0.1549 - val_acc: 0.9627\n",
      "Epoch 31/50\n",
      "34300/34300 [==============================] - 4s 114us/step - loss: 0.1209 - acc: 0.9679 - val_loss: 0.1556 - val_acc: 0.9634\n",
      "Epoch 32/50\n",
      "34300/34300 [==============================] - 5s 136us/step - loss: 0.1217 - acc: 0.9677 - val_loss: 0.1589 - val_acc: 0.9624\n",
      "Epoch 33/50\n",
      "34300/34300 [==============================] - 4s 120us/step - loss: 0.1171 - acc: 0.9686 - val_loss: 0.1642 - val_acc: 0.9620\n",
      "Epoch 34/50\n",
      "34300/34300 [==============================] - 3s 86us/step - loss: 0.1138 - acc: 0.9682 - val_loss: 0.1560 - val_acc: 0.9618\n",
      "Epoch 35/50\n",
      "34300/34300 [==============================] - 3s 92us/step - loss: 0.1196 - acc: 0.9671 - val_loss: 0.1519 - val_acc: 0.9618\n",
      "Epoch 36/50\n",
      "34300/34300 [==============================] - 4s 122us/step - loss: 0.1161 - acc: 0.9690 - val_loss: 0.1664 - val_acc: 0.9600\n",
      "Epoch 37/50\n",
      "34300/34300 [==============================] - 3s 87us/step - loss: 0.1113 - acc: 0.9700 - val_loss: 0.1655 - val_acc: 0.9630\n",
      "Epoch 38/50\n",
      "34300/34300 [==============================] - 4s 121us/step - loss: 0.1156 - acc: 0.9681 - val_loss: 0.1606 - val_acc: 0.9635\n",
      "Epoch 39/50\n",
      "34300/34300 [==============================] - 3s 95us/step - loss: 0.1155 - acc: 0.9683 - val_loss: 0.1587 - val_acc: 0.9624\n",
      "Epoch 40/50\n",
      "34300/34300 [==============================] - 4s 114us/step - loss: 0.1101 - acc: 0.9693 - val_loss: 0.1477 - val_acc: 0.9643\n",
      "Epoch 41/50\n",
      "34300/34300 [==============================] - 4s 114us/step - loss: 0.1115 - acc: 0.9689 - val_loss: 0.1543 - val_acc: 0.9640\n",
      "Epoch 42/50\n",
      "34300/34300 [==============================] - 5s 135us/step - loss: 0.1026 - acc: 0.9715 - val_loss: 0.1613 - val_acc: 0.9624\n",
      "Epoch 43/50\n",
      "34300/34300 [==============================] - 5s 133us/step - loss: 0.1110 - acc: 0.9693 - val_loss: 0.1601 - val_acc: 0.9626\n",
      "Epoch 44/50\n",
      "34300/34300 [==============================] - 3s 92us/step - loss: 0.1077 - acc: 0.9706 - val_loss: 0.1499 - val_acc: 0.9644\n",
      "Epoch 45/50\n",
      "34300/34300 [==============================] - 4s 115us/step - loss: 0.1016 - acc: 0.9720 - val_loss: 0.1609 - val_acc: 0.9628\n",
      "Epoch 46/50\n",
      "34300/34300 [==============================] - 3s 100us/step - loss: 0.1042 - acc: 0.9715 - val_loss: 0.1519 - val_acc: 0.9649\n",
      "Epoch 47/50\n",
      "34300/34300 [==============================] - 4s 107us/step - loss: 0.1027 - acc: 0.9717 - val_loss: 0.1579 - val_acc: 0.9643\n",
      "Epoch 48/50\n",
      "34300/34300 [==============================] - 4s 105us/step - loss: 0.0987 - acc: 0.9733 - val_loss: 0.1525 - val_acc: 0.9647\n",
      "Epoch 49/50\n",
      "34300/34300 [==============================] - 3s 89us/step - loss: 0.1102 - acc: 0.9690 - val_loss: 0.1489 - val_acc: 0.9646\n",
      "Epoch 50/50\n",
      "34300/34300 [==============================] - 3s 88us/step - loss: 0.1025 - acc: 0.9720 - val_loss: 0.1590 - val_acc: 0.9638\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d_with_drop_more_epochs = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 2s 93us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras5.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not much improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"relu\", units=500)`\n",
      "  \n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=500, activation=\"relu\", units=500)`\n",
      "  app.launch_new_instance()\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=500, activation=\"relu\", units=500)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=500, activation=\"relu\", units=500)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=500, activation=\"relu\", units=500)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=500, activation=\"softmax\", units=10)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/25\n",
      "34300/34300 [==============================] - 26s 768us/step - loss: 0.3760 - acc: 0.8810 - val_loss: 0.1576 - val_acc: 0.9564\n",
      "Epoch 2/25\n",
      "34300/34300 [==============================] - 29s 850us/step - loss: 0.1545 - acc: 0.9559 - val_loss: 0.1338 - val_acc: 0.9603\n",
      "Epoch 3/25\n",
      "34300/34300 [==============================] - 27s 795us/step - loss: 0.1157 - acc: 0.9652 - val_loss: 0.1239 - val_acc: 0.9664\n",
      "Epoch 4/25\n",
      "34300/34300 [==============================] - 24s 697us/step - loss: 0.0966 - acc: 0.9712 - val_loss: 0.1033 - val_acc: 0.9716\n",
      "Epoch 5/25\n",
      "34300/34300 [==============================] - 24s 709us/step - loss: 0.0815 - acc: 0.9757 - val_loss: 0.1027 - val_acc: 0.9723\n",
      "Epoch 6/25\n",
      "34300/34300 [==============================] - 29s 835us/step - loss: 0.0702 - acc: 0.9793 - val_loss: 0.1206 - val_acc: 0.9682\n",
      "Epoch 7/25\n",
      "34300/34300 [==============================] - 25s 737us/step - loss: 0.0630 - acc: 0.9812 - val_loss: 0.1140 - val_acc: 0.9690\n",
      "Epoch 8/25\n",
      "34300/34300 [==============================] - 27s 799us/step - loss: 0.0513 - acc: 0.9845 - val_loss: 0.1078 - val_acc: 0.9739\n",
      "Epoch 9/25\n",
      "34300/34300 [==============================] - 27s 795us/step - loss: 0.0478 - acc: 0.9862 - val_loss: 0.1279 - val_acc: 0.9703\n",
      "Epoch 10/25\n",
      "34300/34300 [==============================] - 27s 789us/step - loss: 0.0446 - acc: 0.9871 - val_loss: 0.1196 - val_acc: 0.9721\n",
      "Epoch 11/25\n",
      "34300/34300 [==============================] - 27s 777us/step - loss: 0.0441 - acc: 0.9865 - val_loss: 0.1039 - val_acc: 0.9756\n",
      "Epoch 12/25\n",
      "34300/34300 [==============================] - 27s 787us/step - loss: 0.0399 - acc: 0.9886 - val_loss: 0.0990 - val_acc: 0.9763\n",
      "Epoch 13/25\n",
      "34300/34300 [==============================] - 27s 777us/step - loss: 0.0383 - acc: 0.9892 - val_loss: 0.1059 - val_acc: 0.9754\n",
      "Epoch 14/25\n",
      "34300/34300 [==============================] - 26s 769us/step - loss: 0.0359 - acc: 0.9900 - val_loss: 0.1357 - val_acc: 0.9725\n",
      "Epoch 15/25\n",
      "34300/34300 [==============================] - 27s 790us/step - loss: 0.0378 - acc: 0.9891 - val_loss: 0.1089 - val_acc: 0.9766\n",
      "Epoch 16/25\n",
      "34300/34300 [==============================] - 27s 780us/step - loss: 0.0358 - acc: 0.9901 - val_loss: 0.1051 - val_acc: 0.9750\n",
      "Epoch 17/25\n",
      "34300/34300 [==============================] - 27s 792us/step - loss: 0.0308 - acc: 0.9908 - val_loss: 0.1204 - val_acc: 0.9750\n",
      "Epoch 18/25\n",
      "34300/34300 [==============================] - 27s 788us/step - loss: 0.0283 - acc: 0.9918 - val_loss: 0.1098 - val_acc: 0.9762\n",
      "Epoch 19/25\n",
      "34300/34300 [==============================] - 26s 766us/step - loss: 0.0279 - acc: 0.9922 - val_loss: 0.1087 - val_acc: 0.9790\n",
      "Epoch 20/25\n",
      "34300/34300 [==============================] - 28s 804us/step - loss: 0.0281 - acc: 0.9921 - val_loss: 0.1307 - val_acc: 0.9760\n",
      "Epoch 21/25\n",
      "34300/34300 [==============================] - 27s 795us/step - loss: 0.0274 - acc: 0.9924 - val_loss: 0.1104 - val_acc: 0.9788\n",
      "Epoch 22/25\n",
      "34300/34300 [==============================] - 28s 807us/step - loss: 0.0256 - acc: 0.9927 - val_loss: 0.1372 - val_acc: 0.9756\n",
      "Epoch 23/25\n",
      "34300/34300 [==============================] - 38s 1ms/step - loss: 0.0298 - acc: 0.9919 - val_loss: 0.1095 - val_acc: 0.9795\n",
      "Epoch 24/25\n",
      "34300/34300 [==============================] - 28s 802us/step - loss: 0.0238 - acc: 0.9941 - val_loss: 0.1243 - val_acc: 0.9771\n",
      "Epoch 25/25\n",
      "34300/34300 [==============================] - 28s 806us/step - loss: 0.0278 - acc: 0.9925 - val_loss: 0.1237 - val_acc: 0.9769\n"
     ]
    }
   ],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_deep_n_wide = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 6s 298us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(test_x)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras6.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NOW trying convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (5, 5), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (5, 5), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (4, 4), activation=\"relu\")`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=50, activation=\"softmax\", units=10)`\n",
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/20\n",
      "34300/34300 [==============================] - 57s 2ms/step - loss: 0.4955 - acc: 0.8561 - val_loss: 0.1931 - val_acc: 0.9437\n",
      "Epoch 2/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.1250 - acc: 0.9619 - val_loss: 0.1109 - val_acc: 0.9667\n",
      "Epoch 3/20\n",
      "34300/34300 [==============================] - 41s 1ms/step - loss: 0.0846 - acc: 0.9745 - val_loss: 0.0860 - val_acc: 0.9734\n",
      "Epoch 4/20\n",
      "34300/34300 [==============================] - 42s 1ms/step - loss: 0.0693 - acc: 0.9787 - val_loss: 0.0671 - val_acc: 0.9793\n",
      "Epoch 5/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0557 - acc: 0.9827 - val_loss: 0.0606 - val_acc: 0.9812\n",
      "Epoch 6/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0466 - acc: 0.9853 - val_loss: 0.0559 - val_acc: 0.9827\n",
      "Epoch 7/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0519 - val_acc: 0.9841\n",
      "Epoch 8/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0366 - acc: 0.9887 - val_loss: 0.0621 - val_acc: 0.9798\n",
      "Epoch 9/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0316 - acc: 0.9904 - val_loss: 0.0522 - val_acc: 0.9840\n",
      "Epoch 10/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0558 - val_acc: 0.9831\n",
      "Epoch 11/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0255 - acc: 0.9917 - val_loss: 0.0497 - val_acc: 0.9852\n",
      "Epoch 12/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.0583 - val_acc: 0.9827\n",
      "Epoch 13/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 0.0478 - val_acc: 0.9859\n",
      "Epoch 14/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0494 - val_acc: 0.9867\n",
      "Epoch 15/20\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.0178 - acc: 0.9940 - val_loss: 0.0565 - val_acc: 0.9848\n",
      "Epoch 16/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0491 - val_acc: 0.9871\n",
      "Epoch 17/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.0501 - val_acc: 0.9867\n",
      "Epoch 18/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0130 - acc: 0.9951 - val_loss: 0.0482 - val_acc: 0.9872\n",
      "Epoch 19/20\n",
      "34300/34300 [==============================] - 45s 1ms/step - loss: 0.0114 - acc: 0.9962 - val_loss: 0.0543 - val_acc: 0.9856\n",
      "Epoch 20/20\n",
      "34300/34300 [==============================] - 43s 1ms/step - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0499 - val_acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "# reshape data\n",
    "\n",
    "train_x_temp = train_x.reshape(-1, 28, 28, 1)\n",
    "val_x_temp = val_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# define vars\n",
    "input_shape = (784,)\n",
    "input_reshape = (28, 28, 1)\n",
    "\n",
    "conv_num_filters = 5\n",
    "conv_filter_size = 5\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 20 # first 5, then 10 , 15 \n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "\n",
    " Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 4, 4, activation='relu'),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(train_x_temp, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x_temp, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 12s 576us/step\n"
     ]
    }
   ],
   "source": [
    "test_x_temp = test_x.reshape(-1, 28, 28, 1)\n",
    "pred = model.predict_classes(test_x_temp)\n",
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/Keras10.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "930px",
    "left": "9.32812px",
    "right": "20px",
    "top": "6px",
    "width": "376px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
