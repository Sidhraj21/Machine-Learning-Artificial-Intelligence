{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  In this problem we need to identify the digit in given images. We have total 70,000 images, \n",
    "#out of which 49,000 are part of train images with the label of digit and rest 21,000 images \n",
    "# are unlabeled (known as test images). Now, We need to identify the digit for test images. \n",
    "#Public and Private split for test images are 40:60 and evaluation metric of this challenge is accuracy. \n",
    "\n",
    "#About Data:\n",
    "\n",
    "#The data set used for this problem is from the populat MNIST data set. \n",
    "# Developed by Yann LeCun, Corina Cortes and Christopher Burger for evaluating machine learning model\n",
    "# on the handwritten digit classification problem. It is a widely used data set in the machine learning \n",
    "# community. For more details about the data set, read here http://bit.ly/1REjJgL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the images are 28X28 size and are in .png format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting the warning: RuntimeWarning: compiletime version 3.5 of module \n",
    "#'tensorflow.python.framework.fast_tensor_util' does not match\n",
    "# runtime version 3.6\n",
    "# To supress the warning :\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reproducing the results, setting the seed\n",
    "seed = 34\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the directories: for data, submission\n",
    "\n",
    "root_dir = os.path.abspath('/home/sidhraj/Documents/AV/Identify Digits/')\n",
    "data_dir = os.path.join(root_dir, 'Data')\n",
    "sub_dir = os.path.join(root_dir, 'Submission')\n",
    "\n",
    "# check for existence of the directories\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)\n",
    "os.path.exists(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_dir, 'Sample_Submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBI/hBI/hBI/hBI/hBI/hPoPUl5UxQRVF7IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7686e462e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just to check how the image looks:\n",
    "\n",
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'train', img_name)\n",
    "img = imread(filepath, flatten=True)\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   63.,  105.,  229.,  254.,\n",
       "         254.,  254.,  237.,  105.,  105.,   87.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   22.,  175.,  235.,  254.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  253.,  245.,  121.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   88.,  195.,  253.,  253.,  254.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  248.,  238.,  149.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,  134.,  253.,  253.,  253.,  254.,  253.,  253.,\n",
       "         195.,  133.,  218.,  253.,   93.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   27.,  240.,  253.,  253.,  253.,  179.,   55.,   29.,\n",
       "          16.,    0.,   21.,   29.,    2.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           9.,  145.,  253.,  253.,  253.,  253.,   31.,    6.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          76.,  253.,  253.,  253.,  253.,  253.,  254.,  124.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           4.,  183.,  253.,  253.,  253.,  253.,  255.,  250.,  231.,\n",
       "          48.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,   60.,  232.,  253.,  253.,  253.,  254.,  253.,  253.,\n",
       "         154.,    6.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   56.,  104.,  104.,  192.,  254.,  253.,  253.,\n",
       "         253.,   29.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  194.,  254.,  254.,\n",
       "         254.,   91.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  105.,  253.,  253.,\n",
       "         253.,  178.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    7.,   15.,    6.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  202.,  253.,  253.,\n",
       "         253.,   81.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  176.,  253.,  159.,    0.,\n",
       "           0.,    0.,    0.,    0.,   22.,  120.,  254.,  253.,  253.,\n",
       "         195.,   16.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  254.,  253.,  242.,   40.,\n",
       "           0.,    0.,    0.,   27.,  195.,  253.,  254.,  253.,  249.,\n",
       "          95.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  255.,  253.,  253.,  218.,\n",
       "         179.,   92.,  179.,  206.,  253.,  253.,  255.,  210.,   70.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  254.,  253.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  253.,  253.,  254.,  113.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,  201.,  253.,  253.,  253.,\n",
       "         253.,  253.,  253.,  253.,  237.,  163.,   14.,    3.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,   25.,  220.,  253.,  253.,\n",
       "         213.,  208.,  208.,  155.,   48.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,   86.,  104.,  104.,\n",
       "          12.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img\n",
    "# internal representation of the above image as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Converting the test and train images to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_numpy = []\n",
    "for i in train.filename:  # filename is the ID column in csv file  train\n",
    "    image_path = os.path.join(data_dir, 'train', i) ## train is the folder containing images\n",
    "    image = imread(image_path, flatten=True) ## to remove color from images flatten=True\n",
    "    image = image.astype('float32')\n",
    "    train_numpy.append(image)\n",
    "    \n",
    "train_x = np.stack(train_numpy)\n",
    "\n",
    "test_numpy = []\n",
    "for i in test.filename:\n",
    "    image_path = os.path.join(data_dir, 'test', i)\n",
    "    image = imread(image_path, flatten=True)\n",
    "    image = image.astype('float32')\n",
    "    test_numpy.append(image)\n",
    "    \n",
    "test_x = np.stack(test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating the train and validation set\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train.label.values[:split_size], train.label.values[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## defining function to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating one hot encoding\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "## normalizing values in batches\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"Convert values to range 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    "    \n",
    "    return temp_batch\n",
    "\n",
    "\n",
    "# creating batches for batch processing\n",
    "\n",
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, input_num_units)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    if dataset_name == 'train':\n",
    "        batch_y = eval(dataset_name).ix[batch_mask, 'label'].values\n",
    "        batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a three layer neural network architecture\n",
    "# input layer : image : 28X28X1, if it would have been a color image : 28X28X3\n",
    "# output layer : number of classes 10 : vector size of 10x1\n",
    "# hidden layer : we experiment with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_num_units = 28*28 # input layer\n",
    "hidden_num_units = 500  # hidden layer\n",
    "output_num_units = 10 # output layer\n",
    "\n",
    "\n",
    "# define placeholders\n",
    "x = tf.placeholder(tf.float32, [None, input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "\n",
    "### define weights and biases of the neural network\n",
    "\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network computational graph\n",
    "\n",
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost of neural network \n",
    "#                             labels = True labels                             outpoutput_layer    y\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = output_layer ))\n",
    "\n",
    "# set the optimizer, i.e. backpropogation algorithm. \n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize all the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidhraj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 8.39229\n",
      "Epoch: 2 cost = 1.73185\n",
      "Epoch: 3 cost = 0.92921\n",
      "Epoch: 4 cost = 0.60320\n",
      "Epoch: 5 cost = 0.39541\n",
      "\n",
      "Training complete!\n",
      "Validation Accuracy: 0.956939\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # create initialized variables\n",
    "    sess.run(init)\n",
    "    ## pseudo code for whatever is happening inside the for loop\n",
    "    ### for each epoch, do:\n",
    "    ###   for each batch, do:\n",
    "    ###     create pre-processed batch\n",
    "    ###     run optimizer by feeding batch\n",
    "    ###     find cost and reiterate to minimize\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')\n",
    "            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})\n",
    "            \n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print (\"Epoch:\", (epoch+1), \"cost =\", \"{:.5f}\".format(avg_cost))\n",
    "    \n",
    "    print (\"\\nTraining complete!\")\n",
    "    \n",
    "    \n",
    "    # find predictions on val set\n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    print (\"Validation Accuracy:\", accuracy.eval({x: val_x.reshape(-1, input_num_units), y: dense_to_one_hot(val_y)}))\n",
    "    \n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({x: test_x.reshape(-1, input_num_units)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvfile = \"/home/sidhraj/Documents/AV/Identify Digits/Submission/TF1.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for val in pred:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this model gave approx 96 % accuracy on test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "930px",
    "left": "9.32812px",
    "right": "20px",
    "top": "6px",
    "width": "376px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
